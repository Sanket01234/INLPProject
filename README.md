# Aspectâ€‘Based Sentiment AnalysisÂ (ABSA) Project

Aspectâ€‘Based Sentiment Analysis (ABSA) drills down below overall document sentiment to tell **what** people feel (**sentiment polarity**) about **which parts** of a product or service (**aspects**).  
This repository implements and compares four approaches for ABSA on the SemEvalâ€‘2014 TaskÂ 4 laptop & restaurant review datasets.

![ABSA Visualization Example](outputs/analysis/example_visualization.png)

---

## 1â€¯â€¯Models Implemented

| Model | Brief Description |
|-------|-------------------|
| **Support Vector MachineÂ (SVM)** | Classic linearâ€‘kernel SVM on engineered linguistic features |
| **Logistic RegressionÂ (LR)** | Fast linear classifier baseline |
| **BERT** | Transformer fineâ€‘tuned endâ€‘toâ€‘end for aspectâ€‘level polarity |
| **Hybrid BERT** | BERT sentence embeddingsÂ + engineered features fed to an SVM |

---

## 2â€¯â€¯Key Features

- Endâ€‘toâ€‘end preprocessing pipeline (XML â†’ clean tokenised CSV)
- Feature engineering<br>â€ƒâ€¢ TFâ€‘IDF unigrams/bigramsâ€ƒâ€¢ SentiWordNet scoresâ€ƒâ€¢ Dependencyâ€‘parse relations  
- Unified training / evaluation runners with **JSON metric logs**
- Rich errorâ€‘analysis module producing:<br>â€ƒâ€¢ Sentimentâ€‘distribution piesâ€ƒâ€¢ Aspect frequency barsâ€ƒâ€¢ Word cloudsâ€ƒâ€¢ Modelâ€‘disagreement heatâ€‘maps
- **Autoâ€‘generated interactive HTML report** per domain

---

## 3â€¯â€¯Project Structure

\`\`\`
absa_project/
â”œâ”€ data/                    # Datasets
â”‚  â”œâ”€ raw/                  # Original SemEval XML
â”‚  â””â”€ processed/            # Train/val/test CSV
â”‚
â”œâ”€ preprocessing/
â”‚  â”œâ”€ preprocess.py         # Build train/val/test splits
â”‚  â””â”€ preprocesstest.py    # For unseen test sets
â”‚
â”œâ”€ models/
â”‚  â”œâ”€ traditional/
â”‚  â”‚  â”œâ”€ SVMModel.py
â”‚  â”‚  â””â”€ train_modelLR.py
â”‚  â””â”€ bert/
â”‚     â”œâ”€ bert_classifier.py
â”‚     â””â”€ hybrid_classifier.py
â”‚
â”œâ”€ runners/                 # CLI entrypoints
â”‚  â”œâ”€ run_bert_classifier.py
â”‚  â””â”€ run_hybrid_classifier.py
â”‚
â”œâ”€ utils/
â”‚  â””â”€ aspect_extractor.py
â”‚
â”œâ”€ outputs/
â”‚  â”œâ”€ traditional/          # *.csv predictions & *.json metrics
â”‚  â”œâ”€ bert/
â”‚  â”œâ”€ hybrid/
â”‚  â””â”€ analysis/             # All visualisations & reports
â”‚
â””â”€ README.md
\`\`\`

---

## 4â€¯â€¯Dataset

*SemEvalâ€‘2014 TaskÂ 4*  
- **Laptop** domain reviews  
- **Restaurant** domain reviews  

Each sentence is annotated with one or more \`(aspect, sentiment)\` pairs where sentiment âˆˆ {**positive**, **negative**, **neutral**}.

---

## 5â€¯â€¯Getting Started

### 5.1Â Â Prerequisites

| Package | Version (or newer) |
|---------|--------------------|
| Python | 3.8+ |
| PyTorch | 1.8 |
| transformers | 4.\* |
| scikitâ€‘learn | 0.24 |
| nltk, spacy, seaborn, tabulate, wordcloud, colorama |

### 5.2Â Â Installation

\`\`\`bash
https://github.com/Sanket01234/INLPProject.git
cd INLPProject/

# Set up virtual environment
python3 -m venv venv
source venv/bin/activate          # Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Download NLP resources
python3 -m nltk.downloader punkt averaged_perceptron_tagger sentiwordnet stopwords
python3 -m spacy download en_core_web_sm
\`\`\`

---

## 6â€¯â€¯Pipeline Execution

### 6.1Â Â Preâ€‘process Data

\`\`\`bash
python3 preprocessing/preprocess.py
python3 preprocessing/preprocesstest.py
\`\`\`

### 6.2Â Â Train / Evaluate Models

\`\`\`bash
# Traditional models
python3 models/traditional/SVMModel.py
python3 models/traditional/train_modelLR.py

# BERT fineâ€‘tuning
python3 runners/run_bert_classifier.py

# Hybrid model
python3 runners/run_hybrid_classifier.py
\`\`\`

### 6.3Â Â Analyse Results

\`\`\`bash
# Compare metrics
python3 compare_models.py  

# Generate detailed error analysis + HTML report
python3 error_analysis.py
\`\`\`

---

## 7â€¯â€¯Results & Visualisation

\`outputs/analysis/\` contains

- **Performance metrics**Â (Accuracy, Precision, Recall, F1â€‘macro)
- **Confusion matrices**
- Sentimentâ€‘distribution **pie charts**
- **Aspect frequency** horizontal bars
- **Word clouds** for distinctive tokens
- Interactive **HTML reports** (\`domain_html_report/index.html\`)

---

## 8â€¯â€¯Sample Findings

| Observation | Insight |
|-------------|---------|
| ğŸš€ **Traditional (SVM/LR)** | Very fast training & interpretable weights, but lower recall on minority classes |
| ğŸ¤– **BERT** | Highest accuracy & F1; captures contextual nuances (e.g., â€œkeyboard *light*â€) |
| ğŸ”€ **Hybrid** | Slightly below BERTâ€™s performance yet 2â€‘3Ã— faster inferenceâ€”good tradeâ€‘off for production |

---

## 9â€¯â€¯License

This project is released under the [MIT License](LICENSE).

---

## 10â€¯â€¯Acknowledgements

- **SemEvalâ€‘2014 TaskÂ 4** organisers  
- [Huggingâ€¯Face Transformers](https://huggingface.co/)  
- NLTK & spaCy teams

---

## 11â€¯â€¯Contributors

- **Nikhil Singh, Sanket Madaan, Digvijay Singh Rathore** â€“ initial implementation, model training, visualisation